paths:
  training_data: ""    # Mandatory: Path to input training data
  
  training_labels: ""  # Mandatory: Path to input training labels
  
  testing_data: "" 
  
  testing_labels: "" 
  
  results: "."  # Optional: Path for saving training and evaluation results

  transformation_logic_path: "/home/milad/ML_PATH/my_env/housing_price_predictions/tempoDir/EngineeringAnalysisData_ML/Housing_Price_Prediction/Housing_Data_Processing/california_housing_transformation.py" 
  save_data_path: ""   # leave it empty if you do not want to choose a particular preferred path
  save_labels_path: "" # leave it empty if you do not want to choose a particular preferred path

  data_ingestion_source: https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz

model_config:

  cv: 5
  
  evaluation_metric: ["MAE", "RMSE", "R2"]

  model_name:
    # Uncomment the model you want to use:
    - RandomForestRegressor
    # - LinearRegression
    # - Ridge
    # - Lasso
    # - SVR
    # - GradientBoostingRegressor
    # - XGBoostRegressor
    # - KNeighborsRegressor
    # - DecisionTreeRegressor
    # - AdaBoostRegressor

  model_hyperparameters:
    RandomForestRegressor:
      # Uncomment desired hyperparameters and set values:
      n_estimators: [90, 100]
      max_depth: 4
      min_samples_split: 2
      # min_samples_leaf: 1
      # max_features: "auto"
      # bootstrap: true
      # oob_score: false
      # warm_start: false
      # random_state: 42

    LinearRegression:
      # Uncomment desired hyperparameters and set values:
      # fit_intercept: true
      # normalize: false
      # copy_X: true
      # n_jobs: null
      # positive: false

    Ridge:
      # Uncomment desired hyperparameters and set values:
      # alpha: 1.0
      # fit_intercept: true
      # normalize: false
      # copy_X: true
      # max_iter: null
      # tol: 0.001
      # solver: "auto"
      # random_state: 42

    Lasso:
      # Uncomment desired hyperparameters and set values:
      # alpha: 1.0
      # fit_intercept: true
      # normalize: false
      # precompute: false
      # max_iter: 1000
      # tol: 0.0001
      # warm_start: false
      # positive: false
      # selection: "cyclic"

    SVR:
      # Uncomment desired hyperparameters and set values:
      # kernel: "rbf"
      # degree: 3
      # gamma: "scale"
      # coef0: 0.0
      # tol: 0.001
      # C: 1.0
      # epsilon: 0.1
      # shrinking: true
      # cache_size: 200
      # max_iter: -1

    GradientBoostingRegressor:
      # Uncomment desired hyperparameters and set values:
      # n_estimators: 100
      # learning_rate: 0.1
      # subsample: 1.0
      # criterion: "friedman_mse"
      # min_samples_split: 2
      # min_samples_leaf: 1
      # max_depth: 3
      # max_features: null
      # random_state: 42
      # warm_start: false

    XGBoostRegressor:
      # Uncomment desired hyperparameters and set values:
      # n_estimators: 100
      # learning_rate: 0.1
      # max_depth: 6
      # min_child_weight: 1
      # subsample: 1.0
      # colsample_bytree: 1.0
      # gamma: 0
      # reg_alpha: 0
      # reg_lambda: 1
      # random_state: 42

    KNeighborsRegressor:
      # Uncomment desired hyperparameters and set values:
      # n_neighbors: 5
      # weights: "uniform"
      # algorithm: "auto"
      # leaf_size: 30
      # p: 2
      # metric: "minkowski"
      # metric_params: null
      # n_jobs: null

    DecisionTreeRegressor:
      # Uncomment desired hyperparameters and set values:
      # criterion: "mse"
      # splitter: "best"
      # max_depth: null
      # min_samples_split: 2
      # min_samples_leaf: 1
      # max_features: null
      # random_state: 42
      # max_leaf_nodes: null
      # min_impurity_decrease: 0.0

    AdaBoostRegressor:
      # Uncomment desired hyperparameters and set values:
      # n_estimators: 50
      # learning_rate: 1.0
      # loss: "linear"
      # random_state: 42
